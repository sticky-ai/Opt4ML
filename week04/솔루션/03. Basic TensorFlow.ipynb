{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TensorFlow`는 `Python`안의 다른 언어라고 생각하는 것이 편합니다. 다음과 같은\n",
    "\n",
    "* `numpy`\n",
    "* `scipy`\n",
    "* `scikit-learn`\n",
    "\n",
    "들은 적어도 변수 선언, 대입, 덧셈, 뺄셈, 곱셈, 나눗셈 등이 `Python`과 동일하여 기존 `Python` 유저들이 사용하는데 큰 어려움이 없습니다. 단지, 패키지가 제공하는 함수들의 기능을 숙지하고, 적절한 입력값들을 넣은 후  출력값을 분석에 사용하면 됩니다.\n",
    "\n",
    "하지만, `TensorFlow`에서는 간단한 연산 조차 `TensorFlow`만의 방식으로 작성해야 합니다. 구체적으로 말하면, `Session()`을 통해서 실행해야만 하는 큰 다른 점이 있습니다.\n",
    "\n",
    "이 문서에서는 `TensorFlow`를 사용하여, 기본적인 연산부터, (Pure) 최적화 문제, 그리고 가장 기초적인 딥러닝 예제인 선형 회귀 모델을 구축하는 법을 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaconda에서 Tensorflow 설치하기\n",
    "### OS X or Linux\n",
    "```bash\n",
    "conda create -n fastcampus python=3.5\n",
    "source activate fastcampus\n",
    "conda install pandas matplotlib jupyter notebook scipy scikit-learn tensorflow\n",
    "```\n",
    "### Windows\n",
    "```bash\n",
    "conda create -n fastcampus python=3.5\n",
    "activate fastcampus\n",
    "conda install pandas matplotlib jupyter notebook scipy scikit-learn tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드를 실행하고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Successful import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정상적으로 설치가 완료되면 `Successful import`라고 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산 시작 순간이 다르다!\n",
    "`Hello World!`를 출력하는 코드를 작성하기 위해 가장 먼저 생각할 수 있는 코드는 아래와 같은 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_3:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "hello_constant = tf.constant('Hello World!')\n",
    "print(hello_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hello_constant = tf.constant('Hello World!')`에서 `tf.constant`가 아직 설명되지 않았지만, 기존 파이썬 유저들은 큰 무리 없이 \n",
    "\n",
    "> 아, `Hello World!`라는 String을 선언하는 기능을 하는구나..\n",
    "\n",
    "라고 생각할 수 있습니다. \n",
    "\n",
    "하지만, 출력된 결과를 보면 `Hello World!`가 아닌 `Tensor()`라는 것이 튀어나옵니다. 이것은 마치 파이썬에서 함수를 출력한 결과와 비슷하게 보입니다. 이 결과에서 알 수 있듯, `TensorFlow`는 기존 파이썬과 약간 다른 방식의 접근이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 접근은 바로 `Session()`을 통하여 가능합니다. 아래 코드를 보면서 자세한 설명을 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "hello_constant = tf.constant('Hello World!')\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_constant)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_6:0\", shape=(), dtype=string)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "b'Hello World!'\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "hello_constant = tf.constant('Hello World!')\n",
    "print(hello_constant)\n",
    "print(type(hello_constant))\n",
    "sess =  tf.Session()\n",
    "output = sess.run(hello_constant)\n",
    "print(output)\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`with tf.Session() as sess:`에서 `sess`라는 object를 통하여 모든 실행이 진행됩니다. `sess.run()`을 호출해야만 원했던 결과가 나옵니다. 이를 이해하기 위해서는 연산이 시작되는 위치를 파악 하는 것이 중요합니다. 기존의 파이썬 코드에서는 `python hello.py`를 실행하자마자 연산이 진행되지만, `TensorFlow`를 사용한 코드에서는 `sess.run()`이 실행되는 순간 연산이 진행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수에도 종류가 있다!\n",
    "최적화 문제에서 가장 중요한 loss function의 보면 찾아야할 변수(Weight)와 데이터가 들어가는 변수들로 구성되어있습니다. 선형 회귀로 예를 들면,\n",
    "\n",
    "$$\n",
    "\\min_{w_0,w_1} \\sum_{i=1}^N |w_0x_i + w_1 - y_i|^2\n",
    "$$\n",
    "\n",
    "여기서 저희가 찾아야할 변수들($w_0, w_1$)과 데이터가 들어가는 변수들($x_i$ : train data, $y_i$ : train label)이 있습니다.\n",
    "\n",
    "크게 3가지 종류의 변수가 있습니다.\n",
    "\n",
    "1. [`tf.constant()`](https://www.tensorflow.org/api_docs/python/tf/constant)\n",
    "1. [`tf.placeholder()`](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    "1. [`tf.Variable()`](https://www.tensorflow.org/api_docs/python/tf/Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위의 3가지 변수 종류에 대해서 몇가지 예제와 함께 살펴볼 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant\n",
    "`constant`는 변하지 않는 값을 선언할때 사용합니다. `constant`로 선언된 값을 바꾸려고 하면 에러가 발생합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder\n",
    "Placeholder는 주로 데이터 관련 값들을 표현할때 사용합니다. `palceholder`를 사용하려면 2가지 순서가 있습니다.\n",
    "\n",
    "1. `placeholder`로 선언한다. (변수 타입과 Shape)\n",
    "1. `Session()`의 [`feed_dict`](https://www.tensorflow.org/api_docs/python/tf/Session#run)에 원하는 값을 넣어준다.\n",
    "\n",
    "`Hello World`를 출력하는 예제로 위의 설명을 쉽게 이해할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_constant)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`constant`가 아닌 `placeoholder`로 선언만 바꾸면 에러가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected DataType for argument 'dtype' not 'Hello World!'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type \"Hello World!\" not understood",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_MakeType\u001b[0;34m(v, attr_def)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert {} to a dtype. {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert Hello World! to a dtype. data type \"Hello World!\" not understood",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6243e3e65209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhello_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hello World!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1505\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m       \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1508\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1995\u001b[0m   \"\"\"\n\u001b[1;32m   1996\u001b[0m   result = _op_def_lib.apply_op(\"Placeholder\", dtype=dtype, shape=shape,\n\u001b[0;32m-> 1997\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1998\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    699\u001b[0m           \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_MakeBool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m           \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MakeType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"list(type)\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m           attr_value.list.type.extend(\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_MakeType\u001b[0;34m(v, attr_def)\u001b[0m\n\u001b[1;32m    176\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     raise TypeError(\"Expected DataType for argument '%s' not %s.\" %\n\u001b[0;32m--> 178\u001b[0;31m                     (attr_def.name, repr(v)))\n\u001b[0m\u001b[1;32m    179\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0m_SatisfiesTypeConstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected DataType for argument 'dtype' not 'Hello World!'."
     ]
    }
   ],
   "source": [
    "hello_placeholder = tf.placeholder('Hello World!')\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_placeholder)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feed_dict`를 사용하여 `sess.run()`을 호출해줘야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!!\n"
     ]
    }
   ],
   "source": [
    "hello_placeholder = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_placeholder, feed_dict={hello_placeholder : 'Hello World!!'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feed_dict={hello_placeholder : 'Hello World!!'}`는 `hello_placeholder`라는 변수에 `'Hello World!!'`를 넣어준다(feed)는 의미를 갖는 `run()`의 입력값입니다. 그래서 `placeholder`를 선언할때는 `type`과 `shape`이 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.string`말고 [다른 많은 타입들](https://www.tensorflow.org/versions/r1.1/programmers_guide/dims_types#data_types)이 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello World', y: 123, z: 45.67})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 실행해보면 이상한 점을 발견할 수 있습니다. 기껏, `y` 와 `z`를 선언했지만 `output`에는 `x`값 밖에 나오지 않습니다. 그 이유는 아래의 코드를 보시면 단번에 이해할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World 123 45.66999816894531\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run([x, y, z], feed_dict={x: 'Hello World', y: 123, z: 45.67})\n",
    "xval, yval, zval = output\n",
    "print(xval, yval, zval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sess.run()`의 첫번째 입력인자에는 사용자가 계산(지금은 선언)이 되길 원하는 변수가 들어갑니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable\n",
    "딥러닝에서 가장 핵심적인 정보가 담긴 Weight들은 `tf.Variable`로 선언합니다. `Variable`은 기존의 `Python` 변수들과 가장 유사한 형태로 사용됩니다. 그렇지만, `Varaible`로 선언된 값들을 사용하기 전에 반드시 아래와 같이 `tf.global_variables_initializer()`를 호출해줘야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=() dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 `tf.global_variables_initializer()`를 호출하지 않고 실행한다면 에러가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_2\n\t [[Node: _send_Variable_2_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-2444266377240326787, tensor_name=\"Variable_2:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_2)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_2\n\t [[Node: _send_Variable_2_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-2444266377240326787, tensor_name=\"Variable_2:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8ce559cf3962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda/envs/fastcampus/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_2\n\t [[Node: _send_Variable_2_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-2444266377240326787, tensor_name=\"Variable_2:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_2)]]"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(10)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(10)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    output = sess.run(x)\n",
    "    print(output)\n",
    "    print(type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Math\n",
    "`TensorFlow`에서는 많은 [수학적 연산](https://www.tensorflow.org/api_docs/python/math_ops/)을 제공합니다. `+,-,*,/`처럼 Operator로 정의 되기도 하지만, `tf.add()`, `tf.substract()`, `tf.multiply()`, `tf.divide()`와 같이 함수 형태로도 정의 할 수 있습니다. 함수 형태로 연산을 정의하는 것은 행렬/벡터 곱과 같은 비교적 복잡한 연산을 선언할때 유용합니다.\n",
    "\n",
    "변수 타입이 달라서 생기는 에러는 `tf.cast()`를 사용하여 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_10:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_11:0\", shape=(), dtype=int32)\n",
      "Tensor(\"truediv_1:0\", shape=(), dtype=float64)\n",
      "Tensor(\"sub_1:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = x / y\n",
    "w = z - 1\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Hello World!` 예제와 마찬가지로 `sess.run()`을 해주지 않으면 연산이 시작 되지 않습니다. 여기서 흥미로운 점은 `z`가 숫자로 나올 것 같은데 숫자가 아니고 연산으로 나옵니다.\n",
    "\n",
    "아래 두 예제 코드는 `z`에 표현된 식(addition)을 계산하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(), dtype=int32)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = x + y\n",
    "print(z)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = tf.add(x, y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 1:  스칼라 덧셈\n",
    "$z = x + y$를 실행하는 `TensorFlow`코드를 위에서 배운 3가지 타입을 이용해서 구현해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = x + y\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = x + y\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z, feed_dict={x:10, y:2})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(10, dtype=tf.int32)\n",
    "y = tf.Variable(2, dtype=tf.int32)\n",
    "z = x + y\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    output = sess.run(z, feed_dict={x:10, y:2})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 2 : 벡터 덧셈\n",
    "4차원 벡터 $z = x+y$ 연산을 3가지 타입을 사용하여 구현해봅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_11:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"Const_12:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"Add_1:0\", shape=(4,), dtype=int32)\n",
      "[ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3,4])\n",
    "y = tf.constant([5,6,7,8])\n",
    "z = tf.add(x, y)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_10:0\", dtype=int32)\n",
      "Tensor(\"Placeholder_11:0\", dtype=int32)\n",
      "Tensor(\"Add_2:0\", dtype=int32)\n",
      "[ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.add(x, y)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z, feed_dict={x:[1,2,3,4], y:[5,6,7,8]})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_5:0' shape=(4,) dtype=int32_ref>\n",
      "<tf.Variable 'Variable_6:0' shape=(4,) dtype=int32_ref>\n",
      "Tensor(\"Add_3:0\", shape=(4,), dtype=int32)\n",
      "[ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1,2,3,4])\n",
    "y = tf.Variable([5,6,7,8])\n",
    "z = tf.add(x, y)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    output = sess.run(z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 3 : 행렬/벡터 곱셈\n",
    "$y = Ax + b$를 계산하는 코드를 `numpy`와 `TensorFlow`를 이용하여 작성해봅니다.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\ 2 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 2\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "1\\\\0\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "6\\\\6\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬/벡터 곱은 단순히 `*`으로는 되지 않습니다. `numpy`에서는 `*`는 각 성분끼리 곱셈 연산을 하므로 우리가 원하는 행렬/벡터 곱셈을 하려면 `np.dot()`을 사용해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2,)\n",
      "(2,)\n",
      "[[2 4]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2],[2,2]])\n",
    "x = np.array([1,2])\n",
    "b = np.array([1,0])\n",
    "\n",
    "print(A.shape)\n",
    "print(x.shape)\n",
    "print(b.shape)\n",
    "\n",
    "y = A*x + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.dot()`을 사용해야 행렬/벡터 연산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2,)\n",
      "(2,)\n",
      "[6 6]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2],[2,2]])\n",
    "x = np.array([1,2])\n",
    "b = np.array([1,0])\n",
    "\n",
    "print(A.shape)\n",
    "print(x.shape)\n",
    "print(b.shape)\n",
    "\n",
    "y = np.dot(A, x) + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TensorFlow`도 마찬가지입니다. `tf.matmul()`을 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  4.]\n",
      " [ 3.  4.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.Variable([[1,2],[2,2]], dtype=tf.float32)\n",
    "b = tf.Variable([1,0], dtype=tf.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "y = A*x + b\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    output = sess.run(y, feed_dict={x:[1,2]})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TensorFlow`는 `Tensor`라는 개념아래에서 모든 연산을 진행하기 때문에 shape을 아주 정확하게 넣어줘야합니다.\n",
    "`numpy`를 사용할 때는 \n",
    "```python\n",
    "A = np.array([[1,2],[2,2]])\n",
    "x = np.array([1,2])\n",
    "b = np.array([1,0])\n",
    "```\n",
    "2차원 list와 1차원 list를 혼용해도 상관 없었습니다. 왜냐하면, `numpy`가 알아서 해주기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "[[ 6.  6.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1,2],[2,2]], dtype=tf.float32, shape=(2,2))\n",
    "b = tf.constant([1,0], dtype=tf.float32, shape=(1,2))\n",
    "x = tf.constant([1,2], dtype=tf.float32, shape=(1,2))\n",
    "\n",
    "print(A.shape)\n",
    "print(x.shape)\n",
    "print(b.shape)\n",
    "\n",
    "y = tf.matmul(x,A) + b\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(y)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 에러를 발생시키는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = tf.Variable([[1,2],[2,2]], tf.float32)\n",
    "x = tf.Variable([1,2], tf.float32)\n",
    "b = tf.Variable([1,0], tf.float32)\n",
    "\n",
    "print(A.shape)\n",
    "print(x.shape)\n",
    "print(b.shape)\n",
    "\n",
    "y = tf.matmul(x,A) + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    output = sess.run(y)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 정상 동작하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "[[6 6]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.Variable([[1,2],[2,2]], tf.float32)\n",
    "x = tf.Variable([[1,2]], tf.float32)\n",
    "b = tf.Variable([[1,0]], tf.float32)\n",
    "\n",
    "print(A.shape)\n",
    "print(x.shape)\n",
    "print(b.shape)\n",
    "\n",
    "y = tf.matmul(x,A) + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    output = sess.run(y)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차이는\n",
    "```python\n",
    "x = tf.Variable([1,2], tf.float32)\n",
    "b = tf.Variable([1,0], tf.float32)\n",
    "```\n",
    "와\n",
    "\n",
    "```python\n",
    "x = tf.Variable([[1,2]], tf.float32)\n",
    "b = tf.Variable([[1,0]], tf.float32)\n",
    "```\n",
    "에 있습니다. 알아채셨나요? 첫번째에서는 벡터를 1차원 list를 사용하여 정의했고, 두번째에서는 벡터를 2차원 list로 사용하여 정의했습니다. \n",
    "\n",
    "`TensorFlow`에서는 이렇게 shape을 매우 엄격하게 지켜야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 4 : (Pure) 최적화 문제 풀기\n",
    "`TensorFlow`는 딥러닝 문제를 최적화 시키는 패키지입니다. 그러므로, (Pure) 최적화 문제로 시작하는 것이 자연스럽습니다. \n",
    "\n",
    "이번 예제에서는 아래와 같은 최적화 문제를 풀어봅니다.\n",
    "$$\\min_{x,y} (x-2)^2 + (y-2)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, $x$와 $y$를 `tf.placeholder`와 `tf.Variable`중에 무엇으로 정의를 해야하는지 생각해야합니다. 현재 위의 최적화 문제에서는 $x$와 $y$가 딥러닝에서 weight 역할을 하므로 `tf.Variable`로 선언해야합니다. 간단히 말해서, $\\min$ 기호의 밑에 있는 변수들은 모두 `tf.Variable`로 선언한다고 생각하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(-1.0, dtype=tf.float32)\n",
    "y = tf.Variable(-0.5, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$와 $y$의 초기값은 각각 -1.0과 0.5입니다. 이제 최솟값을 구해야할 loss function을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.square(tf.subtract(x, 2)) + tf.square(tf.subtract(y, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 수치최적화 방법중 가장 기초적인 Gradient Descent Method를 사용하고, hyperparameter 중에 하나인 learning rate은 0.25로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optimizer`를 사용하여, 궁극적인 목적인 최솟값 구하는 것을 표현하는 방법은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 실행하면 Gradient Descent Method를 한 스텝 실행하는 것과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    out = sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간중간, loss값과  $x,y$값을 확인하고 싶다면 아래와 같이 설정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 -0.5 15.25\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    curr_x, curr_y, curr_loss = sess.run([x, y, loss])\n",
    "    print(curr_x, curr_y, curr_loss)\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 최대 Iteration 횟수(15번)를 정하여 돌려봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1.0 -0.5 15.25\n",
      "1 0.5 0.75 3.8125\n",
      "2 1.25 1.375 0.953125\n",
      "3 1.625 1.6875 0.238281\n",
      "4 1.8125 1.84375 0.0595703\n",
      "5 1.90625 1.92188 0.0148926\n",
      "6 1.95312 1.96094 0.00372314\n",
      "7 1.97656 1.98047 0.000930786\n",
      "8 1.98828 1.99023 0.000232697\n",
      "9 1.99414 1.99512 5.81741e-05\n",
      "10 1.99707 1.99756 1.45435e-05\n",
      "11 1.99854 1.99878 3.63588e-06\n",
      "12 1.99927 1.99939 9.08971e-07\n",
      "13 1.99963 1.99969 2.27243e-07\n",
      "14 1.99982 1.99985 5.68107e-08\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(15):\n",
    "        curr_x, curr_y, curr_loss = sess.run([x, y, loss])\n",
    "        print(epoch, curr_x, curr_y, curr_loss)\n",
    "        out = sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력값을 보면, 참값인 $(x,y) = (2,2)$로 수렴하는 것을 알 수 있습니다. 코드를 모아서 보면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1.0 -0.5 15.25\n",
      "1 0.5 0.75 3.8125\n",
      "2 1.25 1.375 0.953125\n",
      "3 1.625 1.6875 0.238281\n",
      "4 1.8125 1.84375 0.0595703\n",
      "5 1.90625 1.92188 0.0148926\n",
      "6 1.95312 1.96094 0.00372314\n",
      "7 1.97656 1.98047 0.000930786\n",
      "8 1.98828 1.99023 0.000232697\n",
      "9 1.99414 1.99512 5.81741e-05\n",
      "10 1.99707 1.99756 1.45435e-05\n",
      "11 1.99854 1.99878 3.63588e-06\n",
      "12 1.99927 1.99939 9.08971e-07\n",
      "13 1.99963 1.99969 2.27243e-07\n",
      "14 1.99982 1.99985 5.68107e-08\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Control Variables\n",
    "x = tf.Variable(-1.0, dtype=tf.float32)\n",
    "y = tf.Variable(-0.5, dtype=tf.float32)\n",
    "# 2. Define Loss function\n",
    "loss = tf.square(tf.subtract(x, 2)) + tf.square(tf.subtract(y, 2))\n",
    "# 3. Choose Numerical Optimizers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.25)\n",
    "# 4. Define Optimization Problem\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 5. Do iterations\n",
    "init = tf.global_variables_initializer() # init for tf.Varaible()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # run initialization\n",
    "    for epoch in range(15):\n",
    "        curr_x, curr_y, curr_loss = sess.run([x, y, loss]) # get current x, y and loss\n",
    "        print(epoch, curr_x, curr_y, curr_loss)\n",
    "        sess.run(train) # train step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 5 : (Pure) 최적화 문제 풀기\n",
    "이번에는 예제코드 없이 직접 아래와 같은 최적화 문제를 풀어봅니다.\n",
    "$$\\min_{x,y} (x + y -2)^2 + (y-1)^2$$\n",
    "참값은 $(x,y) = (1,1)$입니다. 시작값은 $(x,y) = (0.5, 0.5)$로 설정합니다. `learing_rate`과 `MaxIter`는 사용자가 직접 설정해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5 0.5 1.25\n",
      "1 1.0 1.25 0.125\n",
      "2 0.875 1.0 0.015625\n",
      "3 0.9375 1.0625 0.00390625\n",
      "4 0.9375 1.03125 0.00195312\n",
      "5 0.953125 1.03125 0.0012207\n",
      "6 0.960938 1.02344 0.000793457\n",
      "7 0.96875 1.01953 0.000518799\n",
      "8 0.974609 1.01562 0.000339508\n",
      "9 0.979492 1.0127 0.000222206\n",
      "10 0.983398 1.01025 0.000145435\n",
      "11 0.986572 1.0083 9.51886e-05\n",
      "12 0.989136 1.00671 6.23018e-05\n",
      "13 0.991211 1.00543 4.0777e-05\n",
      "14 0.992889 1.00439 2.66889e-05\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Control Variables\n",
    "x = tf.Variable(0.5, dtype=tf.float32)\n",
    "y = tf.Variable(0.5, dtype=tf.float32)\n",
    "# 2. Define Loss function\n",
    "loss = tf.square(tf.subtract(x + y, 2)) + tf.square(tf.subtract(y, 1))\n",
    "# 3. Choose Numerical Optimizers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.25)\n",
    "# 4. Define Optimization Problem\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 5. Do iterations\n",
    "init = tf.global_variables_initializer() # init for tf.Varaible()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # run initialization\n",
    "    for epoch in range(15):\n",
    "        curr_x, curr_y, curr_loss = sess.run([x, y, loss]) # get current x, y and loss\n",
    "        print(epoch, curr_x, curr_y, curr_loss)\n",
    "        sess.run(train) # train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
