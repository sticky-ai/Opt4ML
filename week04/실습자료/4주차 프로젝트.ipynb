{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD를 사용하여 2차 함수 모델 fiiting하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from helper import generate_batches\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "f = lambda x: x**2 + 0.3 * x + 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.linspace(-1, 1, 50)\n",
    "fx = f(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(320)\n",
    "y_train = fx + 0.3 * np.random.rand(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train,y_train, 'o')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Model의 다른 관점 1\n",
    "$$\n",
    "f(x_i,W) = Wx_i =\n",
    "\\begin{bmatrix}\n",
    "w_0& w_1 & w_2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_i^2 \\\\ x_i \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(np.array([[-1.0, -1.0, -1.0]]), dtype=tf.float32)\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.matmul(W, x) - y))\n",
    "\n",
    "batch_size = 10\n",
    "lr = 0.01\n",
    "MaxEpochs = 1000\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "feature_train = np.array([[xval**2, xval, 1] for xval in x_train]).T\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(MaxEpochs):\n",
    "        if epoch % 100 == 0:\n",
    "            curr_w, curr_loss = sess.run([W, loss], feed_dict={x:feature_train, y:y_train})\n",
    "            print(epoch, curr_w,curr_loss)\n",
    "        sess.run(train, feed_dict={x:feature_train, y:y_train})\n",
    "    \n",
    "    w_tf_sgd1 = sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tf_sgd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = np.array([[xval**2, xval, 1] for xval in x_train]).T\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.plot(x_train, np.dot(w_tf_sgd1, feature_train).flatten() , 'r-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Model의 다른 관점 2\n",
    "$$\n",
    "f(x_i,W) = x_iW  =\n",
    "\\begin{bmatrix}\n",
    "x_i^2 & x_i & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_0 \\\\ w_1 \\\\ w_2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "feature_train = [[xval**2, xval, 1.0] for xval in x_train]\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train, y_train)\n",
    "print(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train,y_train, 'o')\n",
    "plt.plot(x_train,reg.predict(feature_train), 'r-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from helper import generate_batches\n",
    "W = tf.Variable(np.array([-1.0, -1.0, -1.0]).reshape(-1,1), dtype=tf.float32)\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None,3))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None,1))\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.matmul(x, W) - y))\n",
    "\n",
    "lr = 0.01\n",
    "MaxEpochs = 1000\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "feature_train = np.array([[xval**2, xval, 1] for xval in x_train])\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(MaxEpochs):\n",
    "        if epoch % 100 == 0:\n",
    "            curr_w, curr_loss = sess.run([W, loss], feed_dict={x:feature_train, y:y_train.reshape(-1,1)})\n",
    "        sess.run(train, feed_dict={x:feature_train, y:y_train.reshape(-1,1)}) # 수정후\n",
    "    w_tf_gd = sess.run(W)\n",
    "print(w_tf_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.plot(x_train, np.dot(feature_train, w_tf_gd).flatten() , 'r-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stochastic Gradient Descent 적용\n",
    "1. 다음과 같이 Parameter를 설정\n",
    "    1. `batch_size=10`\n",
    "    1. `learning_rate=0.01`\n",
    "    1. `w0=np.array([-1.0, -1.0, -1.0])`\n",
    "    1. `MaxEpochs = 1000`\n",
    "1. `np.random.shuffle()` 이용하여 데이터 골고루 섞기\n",
    "1. 아래 for loop 안에 SGD를 구현하시면 됩니다.\n",
    "    ```python\n",
    "    for epoch in range(MaxEpochs):\n",
    "        for x_batch, y_batch in generate_batches(_, _, _):\n",
    "            # do gradient descent with x_batch and y_batch\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(np.array([-1.0, -1.0, -1.0]).reshape(-1,1), dtype=tf.float32)\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None,3))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None,1))\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.matmul(x, W) - y))\n",
    "\n",
    "# TODO1\n",
    "batch_size = None\n",
    "lr = None\n",
    "MaxEpochs = None\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "np.random.seed(320)\n",
    "# TODO2\n",
    "shuffled_id = None\n",
    "np.random.shuffle(None)\n",
    "shuffled_x_train = None\n",
    "shuffled_y_train = None\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(MaxEpochs):\n",
    "        if epoch % 100 == 0:\n",
    "            curr_w, curr_loss = sess.run([W, loss], feed_dict={x:shuffled_x_train, y:shuffled_y_train})\n",
    "            print(epoch, curr_w.flatten(),curr_loss)\n",
    "        # TODO3\n",
    "        None\n",
    "        None\n",
    "\n",
    "    w_tf_sgd = sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = np.array([[xval**2, xval, 1] for xval in x_train])\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.plot(x_train, np.dot(feature_train, w_tf_sgd).flatten() , 'r-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
