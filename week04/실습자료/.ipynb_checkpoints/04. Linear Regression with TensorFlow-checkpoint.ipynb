{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(320)\n",
    "x_train = np.linspace(-1, 1, 51)\n",
    "f = lambda x: 0.5 * x + 1.0\n",
    "y_train = f(x_train) + 0.4 * np.random.rand(len(x_train))\n",
    "\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights(Control Varaible)\n",
    "w = tf.Variable(-1.0, dtype=tf.float32)\n",
    "b = tf.Variable(-1.0, dtype=tf.float32)\n",
    "\n",
    "# Placeholder for Dataset\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# Loss function\n",
    "loss = tf.reduce_sum(tf.square(w * x + b - y))\n",
    "\n",
    "# Numerical Optimizer\n",
    "lr = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all Variables\n",
    "    sess.run(init)\n",
    "    for epoch in range(55):\n",
    "        if epoch % 5 == 0:\n",
    "            # Get w, b, loss\n",
    "            curr_w, curr_b, curr_loss = sess.run([w, b, loss], feed_dict={x:x_train, y:y_train})\n",
    "            print(curr_w, curr_b, curr_loss)\n",
    "        # Do a step of Gradient Descent Method(tf.train.GradientDescentOptimizer)\n",
    "        sess.run(train, feed_dict={x:x_train, y:y_train})\n",
    "    # Get updated Weights\n",
    "    w_tf_gd, b_tf_gd = sess.run([w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.plot(x_train, w_tf_gd * x_train + b_tf_gd, 'r-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit (x_train.reshape(-1,1), y_train)\n",
    "print(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.plot(x_train, reg.predict(x_train.reshape(-1,1)), 'r-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "1. `tf.Varaible` 선언\n",
    "1. `tf.placeholder` 선언\n",
    "1. loss function(손실함수) 선언\n",
    "1. Hyper-Parameter 설정(learning rate, batch size)\n",
    "1. 수치 최적화 알고리즘 선택\n",
    "1. 학습용 데이터 골고루 섞어주기\n",
    "1. Batch마다 Weight(`w`,`b`) 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import generate_batches\n",
    "# Weights(Control Varaible)\n",
    "w = tf.Variable(-1.0, dtype=tf.float32)\n",
    "b = None\n",
    "\n",
    "# Placeholder for Dataset\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = None\n",
    "\n",
    "\n",
    "# TODO 3\n",
    "loss = tf.reduce_sum(tf.square(None))\n",
    "\n",
    "# TODO 4\n",
    "batch_size = 10\n",
    "lr = 0.1\n",
    "\n",
    "# TODO 5\n",
    "optimizer = tf.train.None(lr)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "np.random.seed(320)\n",
    "# TODO 6\n",
    "shuffled_id = np.arange(len(x_train))\n",
    "None\n",
    "shuffled_x_train = None\n",
    "shuffled_y_train = None\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(325):\n",
    "        if epoch % 5 == 0:\n",
    "            curr_w, curr_b, curr_loss = sess.run([w, b, loss], feed_dict={x:x_train, y:y_train})\n",
    "            print(curr_w, curr_b, curr_loss)\n",
    "        # TODO 7\n",
    "        for x_batch, y_batch in generate_batches(batch_size, shuffled_x_train, shuffled_y_train):\n",
    "            sess.run(train, feed_dict={x:None, y:None})\n",
    "    \n",
    "    w_tf_sgd, b_tf_sgd = sess.run([w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.plot(x_train, w_tf_sgd * x_train + b_tf_sgd, 'r-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
