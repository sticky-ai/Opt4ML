{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(W_, xy, labels):\n",
    "    for k, color in [(0, 'b'), (1, 'r')]:\n",
    "        idx = labels.flatten() == k\n",
    "        plt.scatter(xy[idx, 0], xy[idx, 1], c=color)\n",
    "\n",
    "    x1 = np.linspace(-.1, 1.1)\n",
    "    x2 = -W_[1] / W_[2] * x1  - W_[0] / W_[2]\n",
    "    plt.plot(x1, x2, '--k')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeedForward Model\n",
    "$$\\hat{y^{(i)}} = \\sigma(x^{(i)}W)$$\n",
    "1. Feature 정리\n",
    "1. Linear Model\n",
    "$$ z = x W =\n",
    "\\begin{bmatrix}\n",
    "1 & x_1 & x_2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_0 \\\\ w_1 \\\\ w_2\n",
    "\\end{bmatrix}=w_0 + w_1 x_1 + w_2x_2\n",
    "$$\n",
    "1. Sigmoid\n",
    "$$ \\sigma(z)=\\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00. 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([-4./5., 3./4., 1.0])\n",
    "\n",
    "np.random.seed(327)\n",
    "xy = np.random.rand(30,2)\n",
    "labels = np.zeros(len(xy))\n",
    "labels[W[0] + W[1] * xy[:,0] + W[2] * xy[:,1] > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(W, xy, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Feature 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1\n",
    "features = None\n",
    "features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0 = np.array([-0.5, 0.7, 1.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "z = None\n",
    "np.testing.assert_array_almost_equal(z, np.array([ 1.1172906 ,  0.53402258,  1.22390556,  0.19330732,  0.78875462,\n",
    "        1.17346402,  0.30542755,  0.52794582,  0.54884399, -0.06413071,\n",
    "        0.23320688,  0.97782638,  0.51098053,  0.63402059,  0.73668692,\n",
    "        1.68662909,  0.28106909, -0.41730228,  1.01458033,  0.19097579,\n",
    "        0.36345836,  1.06505976,  1.56410043, -0.23806984,  0.83925937,\n",
    "       -0.12982293, -0.27262993,  0.90340202,  0.29225019,  1.31651721]))\n",
    "print(\"Test passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(W0, xy, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Sigmoid\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3\n",
    "sigmoid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(sigmoid(0.7), 0.66818777216816616)\n",
    "print(\"Test3 passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4\n",
    "z =  None\n",
    "model = None\n",
    "np.testing.assert_array_almost_equal(model, np.array([ 0.75348581,  0.63042083,  0.77275013,  0.5481769 ,  0.68756386,\n",
    "        0.76377058,  0.57576879,  0.62900388,  0.63386735,  0.48397281,\n",
    "        0.55803892,  0.72667671,  0.6250363 ,  0.65340056,  0.67627095,\n",
    "        0.84378034,  0.56980831,  0.39716247,  0.73391557,  0.54759937,\n",
    "        0.58987735,  0.74365628,  0.82694095,  0.44076206,  0.69830921,\n",
    "        0.46758978,  0.43226157,  0.71164812,  0.57254693,  0.78860168]))\n",
    "print(\"Test4 passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loss function\n",
    "$$loss(y, \\hat{y}) = \\frac{1}{30}\\sum_{i=1}^{30}-y_i\\log\\hat{y_i}-(1-y_i)\\log(1-\\hat{y_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5\n",
    "def cross_entropy(y, yhat):\n",
    "    val = 0.0\n",
    "    for yi, yhati in zip(y, yhat):\n",
    "        val = None\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = cross_entropy(labels, model)\n",
    "np.testing.assert_array_equal(val, 0.576046231617877)\n",
    "print(\"Test5 passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackPropagation\n",
    "\n",
    "1. sigmoid의 미분\n",
    "1. linear model의 미분\n",
    "1. FeedForward Model의 미분(Chian Rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. sigmoid의 미분\n",
    "\\begin{align}\n",
    "\\sigma'(z) &= \\left[\\frac{1}{1+e^{-z}}\\right]'\\\\\n",
    "&= \\left(-\\frac{1}{(1+e^{-z})^2}\\right) \\cdot \\left(-e^{-z}\\right)\\\\\n",
    "&= \\frac{e^{-z}}{(1+e^{-z})^2}\\\\\n",
    "&= \\frac{1}{1+e^{-z}}\\frac{e^{-z}}{1+e^{-z}}\\\\\n",
    "&= \\frac{1}{1+e^{-z}}\\frac{1 + e^{-z} - 1}{1+e^{-z}}\\\\\n",
    "&= \\frac{1}{1+e^{-z}}\\left(1 - \\frac{1}{1+e^{-z}}\\right)\\\\\n",
    "&= \\sigma(z) (1-\\sigma(z))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_prime = lambda z: sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Linear model의 미분\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial W_j}\\left(xW\\right) &= \\frac{\\partial}{\\partial W_j}\\left(\\sum_{i=1}^d x_iW_i \\right)\\\\\n",
    "&= x_j\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. FeedForward Model의 미분\n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{\\partial}{\\partial W_j}\\hat{y_i} &= \\frac{\\partial}{\\partial W_j}\\sigma(x_iW)\\\\\n",
    "    &= \\frac{\\partial}{\\partial z}\\sigma(z)\\frac{\\partial z}{\\partial W_j}\\\\\n",
    "    &=\\sigma'(z)\\frac{\\partial z}{\\partial W_j}\\\\\n",
    "    &=\\sigma'(z)\\frac{\\partial (x_iW)}{\\partial W_j}\\\\\n",
    "    &=\\sigma(z)(1-\\sigma(z))\\frac{\\partial (x_iW)}{\\partial W_j}\\\\\n",
    "    &=\\sigma(z)(1-\\sigma(z))x_j\\\\\n",
    "    &=\\hat{y_i}(1-\\hat{y_i})x_j\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Backpropagation\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{1}{30}\\sum_{i=1}^{30}\\frac{\\partial}{\\partial W_j}\\left(-y_i\\log\\hat{y_i}-(1-y_i)\\log(1-\\hat{y_i})\\right)\n",
    "&=\\frac{1}{30}\\sum_{i=1}^{30}-(y_i-\\hat{y_i}) x_j\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_loss(W_, features, labels):\n",
    "    val = np.zeros_like(W0)\n",
    "    for xi, yi in zip(features, labels):\n",
    "        # TODO 6\n",
    "        yhati = None\n",
    "        val = None\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = grad_loss(W0, features, labels)\n",
    "np.testing.assert_array_almost_equal(grad, np.array([ 0.16942214, -0.00927518,  0.02356192]))\n",
    "print(\"Test6 passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "MaxEpochs = 1000\n",
    "W0_ = W0\n",
    "for epoch in range(MaxEpochs):\n",
    "    # TODO 7\n",
    "    grad = None\n",
    "    W1 = None\n",
    "    W0_ = None\n",
    "W_gd = W0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_entropy(labels, sigmoid(np.dot(features, W0))))\n",
    "plot_scatter(W0, xy, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_entropy(labels, sigmoid(np.dot(features, W_gd))))\n",
    "plot_scatter(W_gd, xy, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import generate_batches\n",
    "batch_size = 10\n",
    "lr = 0.1\n",
    "MaxEpochs = 1000\n",
    "W0_ = W0\n",
    "\n",
    "# TODO 8\n",
    "idx = np.arange(0, len(features))\n",
    "np.random.shuffle(idx)\n",
    "shuffled_features = features[idx]\n",
    "shuffled_labels = labels[idx]\n",
    "\n",
    "for epoch in range(MaxEpochs):\n",
    "    # TODO 9\n",
    "    for None, None in generate_batches(None, None, None):\n",
    "        grad = None\n",
    "        W1 = None\n",
    "        W0_ = None\n",
    "W_sgd = W0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_entropy(labels, sigmoid(np.dot(features, W_sgd))))\n",
    "plot_scatter(W_sgd, xy, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
