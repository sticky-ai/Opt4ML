{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.pylab import plt\n",
    "from pandas import DataFrame\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(xy, labels, title=\"\"):\n",
    "    # scatter plot, dots colored by class value\n",
    "    df = DataFrame(dict(x=xy[:,0], y=xy[:,1], label=labels))\n",
    "    colors = {1:'red', 0:'blue'}\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    grouped = df.groupby('label')\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, \\\n",
    "                   color=colors[key], edgecolor='k', alpha=0.5)\n",
    "    plt.axis('equal')\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "xy, labels = make_blobs(n_samples=400, center_box=(-1,1), centers=6,cluster_std=0.2, random_state=20)\n",
    "labels = labels % 2\n",
    "plot_scatter(xy, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([[xval, yval] for xval, yval in xy])\n",
    "labels = labels.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test  = train_test_split(features, labels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(features_train, labels_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(features_test, labels_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(sess, model, titles):\n",
    "    train_and_test = [(features_train, labels_train), (features_test, labels_test)]\n",
    "    xx, yy = np.meshgrid(np.linspace(-1.5,1.5), np.linspace(-1.5,1.5))\n",
    "    prediction = sess.run(model, feed_dict={x: np.array([[xxval, yyval] for xxval, yyval in zip(xx.flatten(), yy.flatten())])})\n",
    "    Z = prediction.reshape(xx.shape)\n",
    "    colors = {1:'red', 0:'blue'}\n",
    "    _, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    for (xy_, labels_), ax, title in zip(train_and_test, axes, titles):\n",
    "        df = DataFrame(dict(x=xy_[:,0], y=xy_[:,1], label=labels_.flatten()))\n",
    "        ax.contourf(xx, yy, Z, cmap='coolwarm', alpha=.9,)\n",
    "        grouped = df.groupby('label')\n",
    "        for key, group in grouped:\n",
    "            group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key], edgecolor='k')\n",
    "        ax.set_xlim([-1.3, 1.3])\n",
    "        ax.set_ylim([-1.3, 1.3])\n",
    "        ax.grid(linestyle='--')\n",
    "        ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1 Hyper-Parameters\n",
    "num_hidden1 = 10\n",
    "num_hidden2 = 4\n",
    "learning_rate = 1E-2\n",
    "MaxEpoch = 1500\n",
    "\n",
    "# Model\n",
    "tf.set_random_seed(180417)\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "hidden1 = tf.layers.dense(x, units=num_hidden1, use_bias=True, activation=tf.nn.sigmoid)\n",
    "hidden2 = tf.layers.dense(hidden1, units=num_hidden2, use_bias=True, activation=tf.nn.sigmoid)\n",
    "yhat = tf.layers.dense(hidden2, units=1, use_bias=True, activation=tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.reduce_mean(-y * tf.log(yhat) - (1 - y) * tf.log(1 - yhat))\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "losses1 = []\n",
    "for epoch in range(MaxEpoch):\n",
    "    sess.run(train, feed_dict={x:features_train, y:labels_train})\n",
    "    train_loss = sess.run(loss, feed_dict={x:features_train, y:labels_train})\n",
    "    test_loss = sess.run(loss, feed_dict={x:features_test, y:labels_test})\n",
    "    losses1.append([train_loss, test_loss])\n",
    "    if epoch % 200 == 0:\n",
    "        print(epoch, train_loss, test_loss)\n",
    "        \n",
    "losses1 = np.array(losses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses1[:, 0], label='train')\n",
    "plt.plot(losses1[:, 1], label='test')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(sess, yhat, [\"Train\", \"Test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2 Hyper-Parameters\n",
    "num_hidden1 = None\n",
    "num_hidden2 = None\n",
    "learning_rate = None\n",
    "MaxEpoch = None\n",
    "\n",
    "# Model\n",
    "tf.set_random_seed(180417)\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "hidden1 = tf.layers.dense(x, units=num_hidden1, use_bias=True, activation=tf.nn.sigmoid)\n",
    "hidden2 = tf.layers.dense(hidden1, units=num_hidden2, use_bias=True, activation=tf.nn.sigmoid)\n",
    "yhat = tf.layers.dense(hidden2, units=1, use_bias=True, activation=tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.reduce_mean(-y * tf.log(yhat) - (1 - y) * tf.log(1 - yhat))\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "losses2 = []\n",
    "for epoch in range(MaxEpoch):\n",
    "    sess.run(train, feed_dict={x:features_train, y:labels_train})\n",
    "    train_loss = sess.run(loss, feed_dict={x:features_train, y:labels_train})\n",
    "    test_loss = sess.run(loss, feed_dict={x:features_test, y:labels_test})\n",
    "    losses2.append([train_loss, test_loss])\n",
    "    if epoch % 200 == 0:    \n",
    "        print(epoch, train_loss, test_loss)\n",
    "losses2 = np.array(losses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses2[:, 0], label='train')\n",
    "plt.plot(losses2[:, 1], label='test')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(sess, yhat, [\"Train\", \"Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
