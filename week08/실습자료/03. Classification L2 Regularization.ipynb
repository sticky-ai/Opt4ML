{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.pylab import plt\n",
    "from pandas import DataFrame\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(xy, labels, title=\"\"):\n",
    "    # scatter plot, dots colored by class value\n",
    "    df = DataFrame(dict(x=xy[:,0], y=xy[:,1], label=labels))\n",
    "    colors = {1:'red', 0:'blue'}\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    grouped = df.groupby('label')\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, \\\n",
    "                   color=colors[key], edgecolor='k', alpha=0.5)\n",
    "    plt.axis('equal')\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "xy, labels = make_circles(n_samples=300, noise=0.1, random_state=417)\n",
    "plot_scatter(xy, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train, xy_test, labels_train, labels_test  = train_test_split(xy, labels, test_size = 0.3)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(xy_train, labels_train, title=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(xy_test, labels_test, title='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(batch_size, features, labels):\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "\n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "\n",
    "    return outout_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(sess, model, titles):\n",
    "    train_and_test = [(xy_train, labels_train), (xy_test, labels_test)]\n",
    "    xx, yy = np.meshgrid(np.linspace(-1.5,1.5), np.linspace(-1.5,1.5))\n",
    "    prediction = sess.run(model, feed_dict={x: np.array([[xxval, yyval] for xxval, yyval in zip(xx.flatten(), yy.flatten())])})\n",
    "    Z = prediction.reshape(xx.shape)\n",
    "    colors = {1:'red', 0:'blue'}\n",
    "    _, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    for (xy_, labels_), ax, title in zip(train_and_test, axes, titles):\n",
    "        df = DataFrame(dict(x=xy_[:,0], y=xy_[:,1], label=labels_.flatten()))\n",
    "        ax.contourf(xx, yy, Z, cmap='coolwarm', alpha=.9,)\n",
    "        grouped = df.groupby('label')\n",
    "        for key, group in grouped:\n",
    "            group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key], edgecolor='k')\n",
    "        ax.set_xlim([-1.3, 1.3])\n",
    "        ax.set_ylim([-1.3, 1.3])\n",
    "        ax.grid(linestyle='--')\n",
    "        ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model\n",
    "\n",
    "1. `tf.layers.dense`\n",
    "1. `num_hidden1, num_hidden2 = 10, 4` \n",
    "1. Activation : `tf.nn.sigmoid`\n",
    "1. loss : `tf.reduce_sum(- y * tf.log(yhat) - (1-y) * tf.log(1-yhat) )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(20180417)\n",
    "beta = 0.0\n",
    "num_hidden1, num_hidden2 = 10, 4\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, num_hidden1]))\n",
    "b1 = tf.Variable(tf.random_normal([num_hidden1]))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([num_hidden1, num_hidden2]))\n",
    "b2 = tf.Variable(tf.random_normal([num_hidden2]))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([num_hidden2, 1]))\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hidden1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\n",
    "hidden2 = tf.nn.sigmoid(tf.matmul(hidden1, W2) + b2)\n",
    "\n",
    "yhat = tf.sigmoid(tf.matmul(hidden2, W3) + b3)\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(- y * tf.log(yhat) - (1-y) * tf.log(1-yhat) )\n",
    "l2_regular_loss =  beta * (tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3))\n",
    "\n",
    "loss = cross_entropy + l2_regular_loss\n",
    "\n",
    "lr = 0.01\n",
    "MaxEpoch = 3201\n",
    "\n",
    "train = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for epoch in range(MaxEpoch):\n",
    "    sess.run(train, feed_dict={x:xy_train, y:labels_train.reshape(-1,1)})\n",
    "    \n",
    "    if epoch % 800 == 0:\n",
    "        train_loss, train_loss1, train_loss2 = sess.run([loss, cross_entropy, l2_regular_loss], feed_dict={x:xy_train, y:labels_train.reshape(-1,1)})\n",
    "        test_loss, test_loss1, test_loss2 = sess.run([loss, cross_entropy, l2_regular_loss], feed_dict={x:xy_test, y:labels_test.reshape(-1,1)})\n",
    "        plot_model(sess, yhat, ['(Epoch : {1})\\nTrain loss = {2:4.3E} + {3:4.3E}\\n= {0:4.3E}'.format(train_loss, epoch, train_loss1, train_loss2), \\\n",
    "                                '(Epoch : {1})\\nTest loss = {2:4.3E} + {3:4.3E}\\n= {0:4.3E}'.format(test_loss, epoch, test_loss1, test_loss2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization\n",
    "\n",
    "`l2_regular_loss`는 아래 식을 계산해야합니다.\n",
    "$$\n",
    "\\frac{\\beta}{2}\\sum_{ij} |W^1_{ij}|^2 + \\frac{\\beta}{2}\\sum_{ij} |W^2_{ij}|^2 + \\frac{\\beta}{2}\\sum_{ij} |W^3_{ij}|^2\n",
    "$$\n",
    "\n",
    "다음 함수를 참고하세요\n",
    "- `tf.nn.l2_loss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(- y * tf.log(yhat) - (1-y) * tf.log(1-yhat) )\n",
    "# TODO 1\n",
    "beta = None\n",
    "l2_regular_loss =  None\n",
    "\n",
    "loss = cross_entropy + l2_regular_loss\n",
    "\n",
    "train = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "MaxEpoch = 3201\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for epoch in range(MaxEpoch):\n",
    "    sess.run(train, feed_dict={x:xy_train, y:labels_train.reshape(-1,1)})\n",
    "    \n",
    "    if epoch % 800 == 0:\n",
    "        train_loss, train_loss1, train_loss2 = sess.run([loss, cross_entropy, l2_regular_loss], feed_dict={x:xy_train, y:labels_train.reshape(-1,1)})\n",
    "        test_loss, test_loss1, test_loss2 = sess.run([loss, cross_entropy, l2_regular_loss], feed_dict={x:xy_test, y:labels_test.reshape(-1,1)})\n",
    "        plot_model(sess, yhat, ['(Epoch : {1})\\nTrain loss = {2:4.3E} + {3:4.3E}\\n= {0:4.3E}'.format(train_loss, epoch, train_loss1, train_loss2), \\\n",
    "                                '(Epoch : {1})\\nTest loss = {2:4.3E} + {3:4.3E}\\n= {0:4.3E}'.format(test_loss, epoch, test_loss1, test_loss2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
