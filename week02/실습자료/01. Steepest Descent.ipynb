{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\\begin{equation}\n",
    "f(x) = x^2 - 4x + 6\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 - 4*x + 6\n",
    "\n",
    "# f = lambda x: x**2 - 4*x + 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x)$의 그래프를 그려보기 위해 `np.linspace`를 사용하여 `-5`부터 `5`까지 범위에서 `NumberOfPoints`개 만큼을 같은 간격으로 점을 뽑습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumberOfPoints = 101\n",
    "x = np.linspace(-5., 5, NumberOfPoints)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = f(x)\n",
    "print(fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,fx)\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫번째 시도 : 그냥 다 해보기(Brute Force)\n",
    "모든 점을 다 계산한 후 그중에 가장 작은 값을 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xid = np.argmin(fx)\n",
    "xopt = x[xid]\n",
    "print(xopt, f(xopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,fx)\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(xopt, f(xopt), 'xr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(x, func):\n",
    "    plt.plot(x,func(x))\n",
    "    plt.grid()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.title('plot of f(x)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(x, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째 시도 : Steepest Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With initial $x^{(0)}$, calculate the following equation :\n",
    "\\begin{equation}\n",
    "x^{(k+1)} = x^{(k)} - \\alpha \\nabla f(x^{(k)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fx(x):\n",
    "    return 2*x - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1\n",
    "다음을 식을 이용하여, `x1`을 구하는 코드를 작성하세요.\n",
    "\n",
    "$$\n",
    "x^{(k+1)} = x^{(k)} - \\alpha \\nabla f(x^{(k)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.\n",
    "MaxIter = 100\n",
    "learning_rate = 0.01\n",
    "for i in range(MaxIter):\n",
    "    # TODO 1\n",
    "    x1 = None\n",
    "    print(i, x1, f(x1))\n",
    "    x0 = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(func, grad_func, x0, learning_rate=0.01, MaxIter=10, verbose=True):\n",
    "    paths = []\n",
    "    for i in range(MaxIter):\n",
    "        x1 = x0 - learning_rate * grad_func(x0)\n",
    "        if verbose:\n",
    "            print('{0:03d} : {1:4.3f}, {2:4.2E}'.format(i, x1, func(x1)))\n",
    "        x0 = x1\n",
    "        paths.append(x0)\n",
    "    return(x0, func(x0), paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2\n",
    "\n",
    "`steepest_descent`를 사용하여, 시작 지점은 `0.0`, `learning_rate`은 `1.2`로 Steepest Descent Method를 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "xopt, fopt, paths = steepest_descent(None, None, x0, learning_rate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 2.5, 1000)\n",
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f(paths), 'o-')\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt, fopt, paths = steepest_descent(f, grad_fx, 1.0, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 3.5, 1000)\n",
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f(paths))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3\n",
    "\n",
    "`steepest_descent`를 사용하여, 시작 지점은 `1.0`, `learning_rate`은 `0.001`로 Steepest Descent Method를 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3\n",
    "xopt, fopt, paths = steepest_descent(None, None, None, learning_rate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 3.5, 1000)\n",
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f(paths))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt, fopt, paths = steepest_descent(f, grad_fx, 3.0, learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 3.5, 1000)\n",
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f(paths))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 4\n",
    "\n",
    "`steepest_descent`를 사용하여, 시작 지점은 `3.0`, `learning_rate`은 `1.1`로 Steepest Descent Method를 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4\n",
    "xopt, fopt, paths = steepest_descent(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 10, 1000)\n",
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f(paths))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**2 - 4*x + 6\n",
    "x0 = 0.\n",
    "minimize(f, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(f, x0)\n",
    "print(res.x, res.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Additional) non-convex function\n",
    "\\begin{equation}\n",
    "\\min_x x \\sin(x)\n",
    "\\end{equation}\n",
    "\n",
    "1. Define $f(x)$\n",
    "1. Define $\\nabla f(x)$\n",
    "1. Tune parameters $x_0$, $\\alpha$,MaxIter\n",
    "1. Call `steepest_descent(,,,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 8, 501)\n",
    "f = lambda x : x * np.sin(x)\n",
    "fx = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, fx)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5\n",
    "\n",
    "`grad_f`이름을 갖는 $x \\sin(x)$의 Gradient를 함수를 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5\n",
    "grad_f = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 6\n",
    "\n",
    "`steepest_descent`를 사용하여, 시작 지점은 `1.5`, `learning_rate`은 `0.5`로 Steepest Descent Method를 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6\n",
    "x0 = None\n",
    "xopt, fopt, paths = steepest_descent(f, None, x0, learning_rate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f(paths))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 7\n",
    "\n",
    "`steepest_descent`를 사용하여, 시작 지점은 `7.7`, `learning_rate`은 `0.125`로 Steepest Descent Method를 실행하세요. 최대 Iteration 횟수는 `100`으로 넣어주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 7\n",
    "\n",
    "x0 = None\n",
    "MaxIter = None\n",
    "learning_rate = None\n",
    "\n",
    "xopt, fopt, paths = steepest_descent(f, grad_f, x0, learning_rate=learning_rate, \\\n",
    "                                     MaxIter=MaxIter, verbose=False)\n",
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()\n",
    "plt.plot(f(paths))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = -1.0\n",
    "MaxIter = 100\n",
    "learning_rate = 1.0\n",
    "\n",
    "xopt, fopt, paths = steepest_descent(f, grad_f, x0, learning_rate=learning_rate, MaxIter=MaxIter, verbose=False)\n",
    "paths = np.array(paths)\n",
    "plt.plot(x,f(x))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('plot of f(x)')\n",
    "\n",
    "plt.plot(paths, f(paths), 'o-')\n",
    "plt.show()\n",
    "plt.plot(f(paths))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('cost')\n",
    "plt.title('plot of cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 02\n",
    "\\begin{equation}\n",
    "f(x, y) = (x-2)^2 + (y-2)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax, xstep = -4.0, 4.0, .25\n",
    "ymin, ymax, ystep = -4.0, 4.0, .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y : (x-2)**2 + (y-2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = f(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minima = np.array([2., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(*minima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minima_ = minima.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf(f, x, y, minima=minima_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import contour_with_quiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_f_x = lambda x, y: 2 * (x-2)\n",
    "grad_f_y = lambda x, y: 2 * (y-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_with_quiver(f, x, y, grad_f_x, grad_f_y, minima=minima_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8\n",
    "\n",
    "다음을 식을 이용하여, `x1`을 구하는 코드를 작성하세요.\n",
    "\n",
    "$$\n",
    "x^{(k+1)} = x^{(k)} - \\alpha \\nabla f(x^{(k)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([-2., -2.])\n",
    "MaxIter = 10\n",
    "learning_rate = .25\n",
    "for i in range(MaxIter):\n",
    "    # TODO 8\n",
    "    grad = np.array([grad_f_x(*x0), grad_f_y(*x0)])\n",
    "    x1 = None\n",
    "    fval = f(*x1)\n",
    "    print(i, x1, fval)\n",
    "    x0 = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent_twod(func, gradx, grady, x0, MaxIter=10, learning_rate=0.25, verbose=True):\n",
    "    paths = [x0]\n",
    "    fval_paths = [f(x0[0], x0[1])]\n",
    "    for i in range(MaxIter):\n",
    "        grad = np.array([grad_f_x(*x0), grad_f_y(*x0)])\n",
    "        x1 = x0 - learning_rate * grad\n",
    "        fval = f(*x1)\n",
    "        if verbose:\n",
    "            print(i, x1, fval)\n",
    "        x0 = x1\n",
    "        paths.append(x0)\n",
    "        fval_paths.append(fval)\n",
    "    paths = np.array(paths)\n",
    "    paths = np.array(np.matrix(paths).T)\n",
    "    fval_paths = np.array(fval_paths)\n",
    "    return(x0, fval, paths, fval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([-2., -2.])\n",
    "xopt, fopt, paths, fval_paths = steepest_descent_twod(f, grad_f_x, grad_f_y, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import contour_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_with_path(f, x, y, paths, minima=np.array([[2],[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 03\n",
    "\\begin{equation}\n",
    "f(x, y) = 3(x-2)^2 + (y-2)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y : 3*(x-2)**2 + (y-2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_f_x = lambda x, y: 6 * (x-2)\n",
    "grad_f_y = lambda x, y: 2 * (y-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerical_optimizers import steepest_descent_2d\n",
    "xopt, fopt, paths, fval_paths = steepest_descent_2d(f, grad_f_x, grad_f_y, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf(f, x, y, minima=minima_)\n",
    "# contour_with_quiver(f, x, y, grad_f_x, grad_f_y, minima=minima_)\n",
    "contour_with_path(f, x, y, paths, minima=np.array([[2],[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 04\n",
    "\\begin{equation}\n",
    "f(x, y) = 3(x-2)^2 + (y-2)^4\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y : 3*(x-2)**2 + (y-2)**4\n",
    "\n",
    "# TODO 9\n",
    "grad_f_x = lambda x, y: 6 * (x-2)\n",
    "grad_f_y = lambda x, y: None\n",
    "\n",
    "x0 = np.array([-2., -2.])\n",
    "learning_rate = 0.01\n",
    "\n",
    "xopt, fopt, paths, fval_paths = steepest_descent_2d(f, grad_f_x, grad_f_y, x0, \n",
    "                                                    learning_rate=learning_rate, MaxIter=200, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf(f, x, y, minima=minima_)\n",
    "# contour_with_quiver(f, x, y, grad_f_x, grad_f_y, minima=minima_)\n",
    "contour_with_path(f, x, y, paths, minima=np.array([[2],[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 04\n",
    "\\begin{equation}\n",
    "f(x,y) = \\sin(2\\pi x)\\sin(2\\pi y)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax, xstep = -4.0, 4.0, .0625\n",
    "ymin, ymax, ystep = -4.0, 4.0, .0625\n",
    "x, y = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y : np.sin(np.pi*x) * np.sin(np.pi*y)\n",
    "\n",
    "grad_f_x = lambda x, y: np.pi*np.cos(np.pi*x) * np.sin(np.pi*y)\n",
    "grad_f_y = lambda x, y: np.pi * np.sin(np.pi*x) * np.cos(np.pi*y)\n",
    "\n",
    "learning_rate = 0.01\n",
    "xopt, fopt, paths, fval_paths = steepest_descent_2d(f, grad_f_x, grad_f_y, x0, \n",
    "                                                    learning_rate=learning_rate, MaxIter=200, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf(f, x, y, norm=None)\n",
    "# contour_with_quiver(f, x, y, grad_f_x, grad_f_y, minima=minima_)\n",
    "contour_with_path(f, x, y, paths, norm=None, level=np.linspace(-1, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0, 0.01])\n",
    "xopt, fopt, paths, fval_paths = steepest_descent_2d(f, grad_f_x, grad_f_y, x0, \n",
    "                                                    learning_rate=learning_rate, MaxIter=200, verbose=False)\n",
    "contour_with_path(f, x, y, paths, norm=None, level=np.linspace(-1, 1, 10))\n",
    "xopt, fopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0, -0.01])\n",
    "xopt, fopt, paths, fval_paths = steepest_descent_2d(f, grad_f_x, grad_f_y, x0, \n",
    "                                                    learning_rate=learning_rate, MaxIter=200, verbose=False)\n",
    "contour_with_path(f, x, y, paths, norm=None, level=np.linspace(-1, 1, 10))\n",
    "print(xopt, fopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0, 0.249])\n",
    "learning_rate = 0.025\n",
    "xopt, fopt, paths, fval_paths = steepest_descent_2d(f, grad_f_x, grad_f_y, x0, \n",
    "                                                    learning_rate=learning_rate, MaxIter=200, verbose=False)\n",
    "contour_with_path(f, x, y, paths, norm=None, level=np.linspace(-1, 1, 10))\n",
    "print(xopt, fopt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
