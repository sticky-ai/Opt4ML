{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "f = lambda x: 0.3 * x + 5.0 # Target function\n",
    "x_train = np.linspace(-20, 60, N)\n",
    "np.random.seed(313)\n",
    "y_train = f(x_train) + 10 * np.random.rand(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_train,y_train, 'o')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_w loss(w;x,y)\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "loss(w;x,y) = \\frac{1}{N}\\sum_{i=1}^N |w_0x_i + w_1 - y_i|^2\n",
    "\\end{equation}\n",
    "\n",
    "$loss(w;x,y)$의 Gradient를 구하는 `grad_loss`의 빈칸을 채우세요.\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla loss(w) = \\frac{2}{N}\\sum_{i=1}^N (w_0x_i + w_1 - y_i)\n",
    "\\begin{bmatrix}\n",
    "x_i\\\\1\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(w, x_list, y_list):\n",
    "    N = len(x_list)\n",
    "    val = 0.0\n",
    "    for i in range(N):\n",
    "        val += (w[0] * x_list[i] + w[1] - y_list[i])**2 / N\n",
    "    return val\n",
    "\n",
    "def grad_loss(w, x_list, y_list):\n",
    "    dim = len(w)\n",
    "    N = len(x_list)\n",
    "    val = np.array([0.0, 0.0])\n",
    "    for i in range(N):\n",
    "        # TODO 1\n",
    "        er = None\n",
    "        val += 2.0 * er * None / N\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W0 = np.linspace(-100, 100, 101)\n",
    "W1 = np.linspace(-100, 100, 101)\n",
    "W0, W1 = np.meshgrid(W0,W1)\n",
    "LOSSW = W0 * 0\n",
    "for i in range(W0.shape[0]):\n",
    "    for j in range(W0.shape[1]):\n",
    "        wij = np.array([W0[i,j], W1[i,j]])\n",
    "        LOSSW[i,j] = loss(wij, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper import gradient_descent\n",
    "w0 = np.array([-5.0, -5.0])\n",
    "w_gd, path_gd = gradient_descent(grad_loss, x_train, y_train, w0, learning_rate=1E-3, MaxIter=1000)\n",
    "print(w_gd, loss(w_gd, x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = w_gd[0] * x_train + w_gd[1]\n",
    "plt.plot(x_train,y_train, 'o')\n",
    "plt.plot(x_train, y_pred, '-r')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper import gradient_descent\n",
    "w0 = np.array([-50.0, -50.0])\n",
    "w_gd, path_gd = gradient_descent(grad_loss, x_train, y_train, w0, learning_rate=1E-3, MaxIter=1000)\n",
    "print(w_gd, loss(w_gd, x_train, y_train))\n",
    "\n",
    "paths = path_gd\n",
    "paths = np.array(np.matrix(paths).T)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.contour(W0, W1, LOSSW, cmap=plt.cm.jet, levels=np.linspace(0, max(LOSSW.flatten()),30))\n",
    "ax.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "ax.set_xlabel('$w_0$')\n",
    "ax.set_ylabel('$w_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2\n",
    "\n",
    "Scaling을 구현해봅니다. 알고리즘은 다음과 같이 작성하시면 됩니다.\n",
    "\n",
    "$$\n",
    "\\hat{x} = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "scaled_x_train = None\n",
    "W0 = np.linspace(-100, 100, 101)\n",
    "W1 = np.linspace(-100, 100, 101)\n",
    "W0, W1 = np.meshgrid(W0,W1)\n",
    "LOSSW = W0 * 0\n",
    "LOSSW_Scaled = W0 * 0\n",
    "for i in range(W0.shape[0]):\n",
    "    for j in range(W0.shape[1]):\n",
    "        wij = np.array([W0[i,j], W1[i,j]])\n",
    "        LOSSW[i,j] = loss(wij, x_train, y_train)\n",
    "        LOSSW_Scaled[i,j] = loss(wij, scaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper import gradient_descent\n",
    "w0 = np.array([-50.0, -50.0])\n",
    "w_gd_sc, path_gd_sc = gradient_descent(grad_loss, scaled_x_train, y_train, w0, learning_rate=.5, MaxIter=100)\n",
    "print(w_gd_sc, loss(w_gd_sc, scaled_x_train, y_train))\n",
    "\n",
    "paths = path_gd_sc\n",
    "paths = np.array(np.matrix(paths).T)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.contour(W0, W1, LOSSW_Scaled, cmap=plt.cm.jet, levels=np.linspace(0, max(LOSSW_Scaled.flatten()),30))\n",
    "ax.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "ax.set_xlabel('$w_0$')\n",
    "ax.set_ylabel('$w_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w0 = np.array([-50.0, -50.0])\n",
    "w_gd, path_gd = gradient_descent(grad_loss, x_train, y_train, w0, learning_rate=1E-3, MaxIter=1000)\n",
    "print(w_gd, loss(w_gd, x_train, y_train))\n",
    "\n",
    "w_gd_sc, path_gd_sc = gradient_descent(grad_loss, scaled_x_train, y_train, w0, learning_rate=.5, MaxIter=100)\n",
    "print(w_gd_sc, loss(w_gd_sc, scaled_x_train, y_train))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "paths = path_gd\n",
    "paths = np.array(np.matrix(paths).T)\n",
    "\n",
    "plt.contour(W0, W1, LOSSW, cmap=plt.cm.jet, levels=np.linspace(0, max(LOSSW.flatten()),90))\n",
    "plt.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "plt.xlabel('$w_0$')\n",
    "plt.ylabel('$w_1$')\n",
    "plt.title('original')\n",
    "\n",
    "plt.subplot(222)\n",
    "paths = path_gd_sc\n",
    "paths = np.array(np.matrix(paths).T)\n",
    "\n",
    "plt.contour(W0, W1, LOSSW_Scaled, cmap=plt.cm.jet, levels=np.linspace(0, max(LOSSW_Scaled.flatten()),90))\n",
    "plt.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "plt.xlabel('$w_0$')\n",
    "plt.ylabel('$w_1$')\n",
    "plt.title('scaled')\n",
    "\n",
    "plt.subplot(223)\n",
    "y_pred = w_gd[0] * x_train + w_gd[1]\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.plot(x_train, y_pred, '-r')\n",
    "plt.grid()\n",
    "plt.title('original')\n",
    "\n",
    "plt.subplot(224)\n",
    "y_pred = w_gd_sc[0] * scaled_x_train + w_gd_sc[1]\n",
    "plt.plot(scaled_x_train, y_train, 'o')\n",
    "plt.plot(scaled_x_train, y_pred, '-r')\n",
    "plt.grid()\n",
    "plt.title('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| items | Original Data   | Normalized Data |\n",
    "|------|------|------|\n",
    "|   iteration 횟수  | 1000|100|\n",
    "|   learning_rate | 0.001|0.5|\n",
    "|   loss  | 207.5|7.8|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
