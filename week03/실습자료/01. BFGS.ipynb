{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 최적화 문제를 푸세요.\n",
    "$$\n",
    "\\min_x f(x, y)\n",
    "$$\n",
    "where $f(x,y)=4(x-2)^2 + (y-2)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 4*(x[0] - 2.)**2 + (x[1] - 2.)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1\n",
    "\n",
    "$f(x,y)$의 Gradient인 `grad_f`를 구현하세요.\n",
    "\n",
    "$$\n",
    "\\nabla f(x,y) =(8(x-2), 2(y-2))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_f(x):\n",
    "    # TODO 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "x0 = np.array([8.0, 6.0])\n",
    "res = minimize(f, x0)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2\n",
    "\n",
    "BFGS 알고리즘 중에 다음 수식을 계산하는 코드 중에 빈 곳을 채워넣으세요.\n",
    "\n",
    "$$\n",
    "B_{k+1} = B_{k} + \\frac{y_ky_k^T}{y_k^Ts_k} - \\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_bfgs = []\n",
    "MaxIter = 10\n",
    "learning_rate = 0.5\n",
    "x0 = np.array([8.0, 6.0])\n",
    "path_bfgs.append(x0)\n",
    "B0 = np.eye(len(x0))\n",
    "for i in range(MaxIter):\n",
    "    print(x0)\n",
    "    grad = grad_f(x0)\n",
    "    if np.linalg.norm(grad) < 1E-9:\n",
    "        break\n",
    "    p0 = -np.linalg.solve(B0, grad)\n",
    "    s0 = learning_rate * p0\n",
    "    x1 = x0 + s0\n",
    "    y0 = (grad_f(x1) - grad).reshape(-1,1)# convert to a column vector\n",
    "    # TODO 2\n",
    "    B1 = B0 + None \\\n",
    "            - (np.dot(np.dot(B0, s0).reshape(-1,1), np.dot(s0, B0).reshape(-1,1).T)) / np.dot(np.dot(B0, s0), s0)\n",
    "    x0 = x1\n",
    "    path_bfgs.append(x0)\n",
    "    B0 = B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = path_bfgs\n",
    "paths = np.array(np.matrix(paths).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-20, 10, 101)\n",
    "y = np.linspace(-20, 10, 101)\n",
    "X,Y = np.meshgrid(x, y)\n",
    "f = lambda x, y : 4*(x-2)**2 + (y-2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.contour(X, Y, f(X,Y), cmap=plt.cm.jet, levels=np.linspace(0, max(f(X,Y).flatten()),30))\n",
    "ax.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "ax.set_xlabel('$w_0$')\n",
    "ax.set_ylabel('$w_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3가지 방법 비교\n",
    "1. Steepest Descent(Gradient Descent) Method\n",
    "1. Newton Method\n",
    "1. BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = np.array([1, 1])\n",
    "path_gd = []\n",
    "MaxIter = 500\n",
    "learning_rate = 0.1\n",
    "x0 = np.array([8.0, 6.0])\n",
    "path_gd.append(x0)\n",
    "for i in range(MaxIter):\n",
    "    grad = grad_f(x0)\n",
    "    if np.linalg.norm(grad) < 1E-9:\n",
    "        break\n",
    "    x1 = x0 - learning_rate * grad\n",
    "    x0 = x1\n",
    "    path_gd.append(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = path_gd\n",
    "paths = np.array(np.matrix(paths).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.contour(X, Y, f(X,Y), cmap=plt.cm.jet, levels=np.linspace(0, max(f(X,Y).flatten()),30))\n",
    "ax.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "ax.set_xlabel('$w_0$')\n",
    "ax.set_ylabel('$w_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3\n",
    "\n",
    "Newton Method의 사용을 위해 $f(x,y)$의 Hessian인 `hessian_f`를 구현하세요.\n",
    "\n",
    "$$\n",
    "f(x,y)=4(x-2)^2 + (y-2)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla^2 f(x,y) = ?\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hessian_f(x):\n",
    "    # TODO 3\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = np.array([1, 1])\n",
    "path_nt = []\n",
    "MaxIter = 100\n",
    "learning_rate = 1\n",
    "x0 = np.array([8.0, 6.0])\n",
    "path_nt.append(x0)\n",
    "for i in range(MaxIter):\n",
    "    grad = grad_f(x0)\n",
    "    hess = hessian_f(x0)\n",
    "    if np.linalg.norm(grad) < 1E-9:\n",
    "        break\n",
    "    x1 = x0 - learning_rate * np.linalg.solve(hess,grad)\n",
    "    x0 = x1\n",
    "    path_nt.append(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = path_nt\n",
    "paths = np.array(np.matrix(paths).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.contour(X, Y, f(X,Y), cmap=plt.cm.jet, levels=np.linspace(0, max(f(X,Y).flatten()),30))\n",
    "ax.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "ax.set_xlabel('$w_0$')\n",
    "ax.set_ylabel('$w_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.subplot(131)\n",
    "paths = path_gd\n",
    "paths = np.array(np.matrix(paths).T)\n",
    "plt.contour(X, Y, f(X,Y), cmap=plt.cm.jet, levels=np.linspace(0, max(f(X,Y).flatten()),30))\n",
    "plt.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "plt.plot(2, 2, 'r*')\n",
    "plt.title('Gradient Method : iteration = {0}'.format(len(path_gd)))\n",
    "plt.xlabel('$w_0$')\n",
    "plt.ylabel('$w_1$')\n",
    "\n",
    "plt.subplot(132)\n",
    "paths = path_nt\n",
    "paths = np.array(np.matrix(paths).T)\n",
    "plt.contour(X, Y, f(X,Y), cmap=plt.cm.jet, levels=np.linspace(0, max(f(X,Y).flatten()),30))\n",
    "plt.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "plt.plot(2, 2, 'r*')\n",
    "plt.title('Newton Method : iteration = {0}'.format(len(path_nt)))\n",
    "plt.xlabel('$w_0$')\n",
    "plt.ylabel('$w_1$')\n",
    "\n",
    "plt.subplot(133)\n",
    "paths = path_bfgs\n",
    "paths = np.array(np.matrix(paths).T)\n",
    "plt.contour(X, Y, f(X,Y), cmap=plt.cm.jet, levels=np.linspace(0, max(f(X,Y).flatten()),30))\n",
    "plt.quiver(paths[0,:-1], paths[1,:-1], paths[0,1:]-paths[0,:-1], paths[1,1:]-paths[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "plt.plot(2, 2, 'r*')\n",
    "plt.title('BFGS Method : iteration = {0}'.format(len(path_bfgs)))\n",
    "plt.xlabel('$w_0$')\n",
    "plt.ylabel('$w_1$')\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|items| Gradient Descent   | Newton | BFGS |\n",
    "|------|------|------|------|\n",
    "|   iteration 횟수  | 104|2|11|\n",
    "|   gradient 계산  | O|O|O|\n",
    "|   hessian 계산  | X|O|X|\n",
    "|   linear system 풀이  | X|O|O|\n",
    "|   속도  | 느림|빠름|보통|\n",
    "|   안정성  | 높음|많이 낮음|낮음|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
