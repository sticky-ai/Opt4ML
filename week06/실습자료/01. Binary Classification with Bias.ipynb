{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(W_, xy, labels):\n",
    "    for k, color in [(0, 'b'), (1, 'r')]:\n",
    "        idx = labels.flatten() == k\n",
    "        plt.scatter(xy[idx, 0], xy[idx, 1], c=color)\n",
    "\n",
    "    if W_ is not None:\n",
    "        x1 = np.linspace(-.1, 1.1)\n",
    "        x2 = -W_[1] / W_[2] * x1  - W_[0] / W_[2]\n",
    "        plt.plot(x1, x2, '--k')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(402)\n",
    "xy = np.random.rand(30,2)\n",
    "labels = np.zeros((len(xy),1))\n",
    "labels[-4./5. +  3./4. * xy[:,0] + 1.0 * xy[:,1] > 0, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(None, xy, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "$$\n",
    "\\min_{W,b} \\frac{1}{m}\\sum_{i=1}^m -y_i \\log(\\hat{y_i})-(1-y_i) \\log(1-\\hat{y_i})\n",
    "$$\n",
    "where $\\hat{y_i} = \\sigma(x_i W + b)$\n",
    "\n",
    "1. Forward Model : $\\hat{y_i} = \\sigma(x_i W + b)$\n",
    "1. Cross-Entropy : $\\frac{1}{m}\\sum_{i=1}^m -y_i \\log(\\hat{y_i})-(1-y_i) \\log(1-\\hat{y_i})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Model에 맞는 feature 정리\n",
    "For $i=1,2,\\cdots,m$,\n",
    "$$\n",
    "\\texttt{features}_i = [x_i, y_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO1\n",
    "features = np.array([[xval, yval] for xval, yval in xy])\n",
    "features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Model TensorFlow로 정의하기\n",
    "\n",
    "- TODO2 : `features`를 `feed`할 placeholder(`x`)를 정의\n",
    "- TODO3 : Weight(`W`)와 bias(`b`)를 `Variable`로 초기값 1로 정의\n",
    "- TODO4 : Model(`model`) 정의\n",
    "\n",
    "$$\n",
    "\\hat{y_i} = \\sigma(x_i W + b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO2\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "\n",
    "# TODO3\n",
    "W = tf.Variable(tf.ones([2 ,1]), dtype=tf.float32)\n",
    "b = tf.Variable(tf.ones([1]), dtype=tf.float32)\n",
    "\n",
    "print(W.shape)\n",
    "print(b.shape)\n",
    "\n",
    "# TODO4\n",
    "model = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "print(model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드를 돌려 에러가 나지 않으면 정답입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY CODE BELOW\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "model_val = sess.run(model, feed_dict={x:features})\n",
    "model_val.flatten()\n",
    "np.testing.assert_array_almost_equal(model_val.flatten(), np.array([ 0.82164884,  0.90143549,  0.88008773,  0.94627064,  0.9076525 ,\n",
    "        0.87884021,  0.88706684,  0.94524395,  0.91657001,  0.92202485,\n",
    "        0.84915382,  0.88213223,  0.89813203,  0.91223586,  0.83902246,\n",
    "        0.9068526 ,  0.78098732,  0.77686596,  0.8815819 ,  0.88183749,\n",
    "        0.79339015,  0.93020332,  0.77778834,  0.80740386,  0.90895367,\n",
    "        0.85820019,  0.89018804,  0.82814378,  0.89006978,  0.91128868]))\n",
    "print(\"Test passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Cross-Entropy 정의하기\n",
    "\n",
    "- TODO5 : `labels`를 `feed`할 `placeholder`(`y`) 정의하기\n",
    "- TODO6 : Corss-Entropy(`loss`) 정의하기\n",
    "\n",
    "$$\n",
    " \\frac{1}{m}\\sum_{i=1}^m -y_i \\log(\\hat{y_i})-(1-y_i) \\log(1-\\hat{y_i})\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "# TODO 6\n",
    "loss = tf.reduce_mean( - y * tf.log(model) - (1-y) * tf.log((1 - model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드를 돌려 에러가 나지 않으면 정답입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY CODE BELOW\n",
    "loss_val = sess.run(loss, feed_dict={x:features, y:labels})\n",
    "np.testing.assert_almost_equal(loss_val, 0.69793868)\n",
    "print(\"Test passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Hyper-Parameter 설정(TODO 7)\n",
    "1. Optimizer : `AdamOptimizer`\n",
    "1. `lerning rate` : `0.1`\n",
    "1. `MaxEpoch` : `201`\n",
    "1. Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 7\n",
    "lr = None\n",
    "MaxEpochs= None\n",
    "optimizer = None\n",
    "train = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. Gradient Descent\n",
    "\n",
    "- TODO8 : batch 사용하지 않고 모든 features와 labels을 다 feed 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    out = sess.run([model, loss], feed_dict={x: features, y: labels})\n",
    "    for epoch in range(MaxEpochs):\n",
    "        if epoch % 50 == 0 :\n",
    "            curr_b, curr_W, curr_loss = sess.run([b, W, loss], feed_dict={x: features, y: labels})\n",
    "            print(epoch, curr_b.flatten(), curr_W.flatten(), curr_loss)\n",
    "        # TODO 8\n",
    "        None\n",
    "    curr_b, curr_W = sess.run([b, W])\n",
    "W_gd = curr_W.flatten()\n",
    "b_gd = curr_b.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(np.append(b_gd, W_gd), xy, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06. Stochastic Gradient Descent(SGD)\n",
    "- TODO9 : shuffle training set\n",
    "- TODO10 : batch 생성하기\n",
    "- TODO11 : batch만 사용하여, train 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import generate_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9\n",
    "idx = None\n",
    "shuffled_features = None\n",
    "shuffled_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    out = sess.run([model, loss], feed_dict={x: shuffled_features, y: shuffled_labels})\n",
    "    for epoch in range(MaxEpochs):\n",
    "        if epoch % 50 == 0 :\n",
    "            curr_b, curr_W, curr_loss = sess.run([b, W, loss], feed_dict={x: shuffled_features, y: shuffled_labels})\n",
    "            print(epoch, curr_b.flatten(), curr_W.flatten(), curr_loss)\n",
    "        # TODO 10\n",
    "        None\n",
    "            # TODO 11\n",
    "            None\n",
    "\n",
    "    curr_b, curr_W = sess.run([b, W])\n",
    "W_sgd = curr_W.flatten()\n",
    "b_sgd = curr_b.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(np.append(b_sgd, W_sgd), xy, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
